{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1690897011385,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "L3BsTnrCHY-L",
    "outputId": "aff39c0f-c452-44be-bf93-c5523bd2a90f"
   },
   "outputs": [],
   "source": [
    "#pip3 install google.colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yTrysaRSfO7"
   },
   "source": [
    "###  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "executionInfo": {
     "elapsed": 1500,
     "status": "error",
     "timestamp": 1690897017322,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "A6Xgfba5SeYG",
    "outputId": "3a3e4f3b-54d5-4379-d747-d27332446691"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from Autoencoder import Autoencoder, CD_Autoencoder\n",
    "from Datasets.Datasets_Functions import *\n",
    "from Visualization import Visualization\n",
    "from Evaluations.Evaluation import Evaluator\n",
    "from General_Functions import General_Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4OhuI9Y_mBT"
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "aborted",
     "timestamp": 1690896732863,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "q41qJCN0_mBU"
   },
   "outputs": [],
   "source": [
    "path_to_module = './' # 'C:\\\\Users\\\\PAPASOFT INC\\\\Desktop\\\\SOFT_SIL'\n",
    "sys.path.append(path_to_module)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = Visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjskwTndC-y-"
   },
   "source": [
    "### ***LOAD DATASET***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "aborted",
     "timestamp": 1690896732864,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "6nFI8NEPhs0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashmap file not found.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'emnist_balanced_letters' not found in dictionary.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m hashmap \u001b[38;5;241m=\u001b[39m get_hashmap(hashmap_path)\n\u001b[0;32m      4\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memnist_balanced_letters\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mupdate_inner_hashmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_clusters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpath_to_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m dataset_properties \u001b[38;5;241m=\u001b[39m hashmap[dataset_name]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_properties)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Soft-Silhouette\\Datasets\\Datasets_Functions.py:115\u001b[0m, in \u001b[0;36mupdate_inner_hashmap\u001b[1;34m(keys, new_value, file_path)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeys[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in dictionary.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeys[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in dictionary.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    118\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(hashmap, file)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'emnist_balanced_letters' not found in dictionary.\""
     ]
    }
   ],
   "source": [
    "hashmap_path = path_to_module + 'Datasets/'\n",
    "hashmap = get_hashmap(hashmap_path)\n",
    "\n",
    "dataset_name = 'emnist_balanced_letters'\n",
    "update_inner_hashmap([dataset_name,'n_clusters'],10,path_to_module)\n",
    "dataset_properties = hashmap[dataset_name]\n",
    "print(dataset_properties)\n",
    "\n",
    "dataloader, input_dim, data_np, labels = function_get_dataset(dataset_name, dataset_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5uxFA6rSfOv"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "aborted",
     "timestamp": 1690896732865,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "ND4kEAYMDTim"
   },
   "outputs": [],
   "source": [
    "# Latent Dimension, Number of Channels and Negative Slope\n",
    "latent_dim = 2\n",
    "n_channels = 1\n",
    "n_clusters = dataset_properties['n_clusters']\n",
    "\n",
    "# Batch Size and Number of Clusters\n",
    "batch_size = dataset_properties['batch_size']\n",
    "negative_slope = 0\n",
    "\n",
    "# Pre-Training Epochs and Learning Rate\n",
    "n_pret_epochs = 100\n",
    "pret_lr = 1e-3\n",
    "\n",
    "# Lamdas, Training Epochs and Learning Rate\n",
    "n_epochs = 100\n",
    "lr = 5e-4\n",
    "sil_lambda = 0.02\n",
    "entr_lambda = 0.02\n",
    "\n",
    "kmeans_initialization = False\n",
    "pretrain = False\n",
    "is_MLP_AE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2P-UOuHDOXV"
   },
   "source": [
    "### Create Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "aborted",
     "timestamp": 1690896732866,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "PBkI9U0tgoZ1"
   },
   "outputs": [],
   "source": [
    "if is_MLP_AE:\n",
    "    autoencoder = Autoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, negative_slope=negative_slope)\n",
    "    autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "    autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "    autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, sil_lambda=sil_lambda, entr_lambda=entr_lambda)\n",
    "    autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "    autoencoder.set_path()\n",
    "else:\n",
    "    autoencoder = CD_Autoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, negative_slope=negative_slope, n_channels=n_channels)\n",
    "    autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "    autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "    autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, sil_lambda=sil_lambda, entr_lambda=entr_lambda)\n",
    "    autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "    autoencoder.set_path()\n",
    "\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder_model): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=500, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=500, out_features=2000, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (8): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=2000, out_features=2, bias=True)\n",
       "    (10): Tanh()\n",
       "    (11): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cluster_model): Sequential(\n",
       "    (0): RBF()\n",
       "  )\n",
       "  (decoder_model): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=2000, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=2000, out_features=500, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (8): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (10): LeakyReLU(negative_slope=0, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Results/emnist_balanced_letters/AE/100_Eps_ld_2_out_37_bs_256_lr_0.0005_sil_lambda_0.02_entr_lambda_0.02/Weigths/autoencoder_weights.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     model_save_path \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mdata_dir_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Weigths/autoencoder_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m     autoencoder\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Results/emnist_balanced_letters/AE/100_Eps_ld_2_out_37_bs_256_lr_0.0005_sil_lambda_0.02_entr_lambda_0.02/Weigths/autoencoder_weights.pth'"
     ]
    }
   ],
   "source": [
    "if(pretrain):\n",
    "    autoencoder.pretrain_autoencoder()\n",
    "    autoencoder.save_pretrained_weights()\n",
    "else:\n",
    "    model_save_path = autoencoder.data_dir_path + '/Weigths/autoencoder_weights.pth'\n",
    "    autoencoder.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the clustering layer using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inits = 100\n",
    "if kmeans_initialization: autoencoder.kmeans_initialization(n_inits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "aborted",
     "timestamp": 1690896732869,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "GVXfROTxGNJ2"
   },
   "outputs": [],
   "source": [
    "autoencoder.set_training_variables(n_epochs=20, lr=5e-4, sil_lambda=0.02, entr_lambda=0.02)\n",
    "latent_data, labels, clustering = autoencoder.train_autoencoder()\n",
    "cluster_centers = autoencoder.get_cluster_centers().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.plot_tsne(latent_data, labels, clustering, cluster_centers, autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.plot(latent_data, labels, clustering, cluster_centers, autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_Functions().save_excel(autoencoder.data_dir_path, autoencoder.df_eval)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "121w-F_LopS2b6ATyJPxh0a_i4mceFfzN",
     "timestamp": 1688385039773
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
