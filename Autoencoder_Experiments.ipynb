{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1690897011385,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "L3BsTnrCHY-L",
    "outputId": "aff39c0f-c452-44be-bf93-c5523bd2a90f"
   },
   "outputs": [],
   "source": [
    "#pip3 install google.colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yTrysaRSfO7"
   },
   "source": [
    "###  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "executionInfo": {
     "elapsed": 1500,
     "status": "error",
     "timestamp": 1690897017322,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "A6Xgfba5SeYG",
    "outputId": "3a3e4f3b-54d5-4379-d747-d27332446691"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from Autoencoder import Autoencoder, CD_Autoencoder\n",
    "from Datasets.Datasets_Functions import *\n",
    "from Visualization import Visualization\n",
    "from Evaluations.Evaluation import Evaluator\n",
    "from General_Functions import General_Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4OhuI9Y_mBT"
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "aborted",
     "timestamp": 1690896732863,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "q41qJCN0_mBU"
   },
   "outputs": [],
   "source": [
    "path_to_module = './' # 'C:\\\\Users\\\\PAPASOFT INC\\\\Desktop\\\\SOFT_SIL'\n",
    "sys.path.append(path_to_module)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = Visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjskwTndC-y-"
   },
   "source": [
    "### ***LOAD DATASET***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "aborted",
     "timestamp": 1690896732864,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "6nFI8NEPhs0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1024, 'n_clusters': 10, 'module_name': 'Datasets.Datasets'}\n",
      "Data_Shape is: 1\n",
      "Batches Number is: 28\n"
     ]
    }
   ],
   "source": [
    "hashmap_path = path_to_module + 'Datasets/'\n",
    "hashmap = get_hashmap(hashmap_path)\n",
    "dataset_name = 'emnist_balanced_letters'\n",
    "update_inner_hashmap([dataset_name,'batch_size'],1024,hashmap_path)\n",
    "dataset_properties = hashmap[dataset_name]\n",
    "print(dataset_properties)\n",
    "\n",
    "dataloader, input_dim, data_np, labels = function_get_dataset(dataset_name, dataset_properties)\n",
    "print('Data_Shape is:', input_dim)\n",
    "print('Batches Number is:', len(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5uxFA6rSfOv"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "aborted",
     "timestamp": 1690896732865,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "ND4kEAYMDTim"
   },
   "outputs": [],
   "source": [
    "# Latent Dimension, Number of Channels and Negative Slope\n",
    "latent_dim = 10\n",
    "n_channels = 1\n",
    "n_clusters = dataset_properties['n_clusters']\n",
    "\n",
    "# Batch Size and Number of Clusters\n",
    "batch_size = dataset_properties['batch_size']\n",
    "negative_slope = 0\n",
    "\n",
    "# Pre-Training Epochs and Learning Rate\n",
    "n_pret_epochs = 100\n",
    "pret_lr = 1e-3\n",
    "\n",
    "# Lamdas, Training Epochs and Learning Rate\n",
    "n_epochs = 100\n",
    "lr = 5e-4\n",
    "sil_lambda = 0.02\n",
    "entr_lambda = 0.02\n",
    "\n",
    "kmeans_initialization = True\n",
    "pretrain = True\n",
    "is_MLP_AE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2P-UOuHDOXV"
   },
   "source": [
    "### Create Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "aborted",
     "timestamp": 1690896732866,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "PBkI9U0tgoZ1"
   },
   "outputs": [],
   "source": [
    "if is_MLP_AE:\n",
    "    autoencoder = Autoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, negative_slope=negative_slope)\n",
    "    autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "    autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "    autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, sil_lambda=sil_lambda, entr_lambda=entr_lambda)\n",
    "    autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "    autoencoder.set_path()\n",
    "else:\n",
    "    autoencoder = CD_Autoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, negative_slope=negative_slope, n_channels=n_channels)\n",
    "    autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "    autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "    autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, sil_lambda=sil_lambda, entr_lambda=entr_lambda)\n",
    "    autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "    autoencoder.set_path()\n",
    "\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CD_Autoencoder(\n",
       "  (encoder_model): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (4): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (7): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=1152, out_features=10, bias=True)\n",
       "    (11): Tanh()\n",
       "    (12): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (cluster_model): Sequential(\n",
       "    (0): RBF()\n",
       "  )\n",
       "  (decoder_model): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=1152, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (2): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Unflatten(dim=1, unflattened_size=(128, 3, 3))\n",
       "    (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (5): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ConvTranspose2d(32, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0, inplace=True)\n",
       "    (12): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 20.638789\n",
      "Epoch: 1, Loss: 15.330878\n",
      "Epoch: 2, Loss: 13.348399\n",
      "Epoch: 3, Loss: 11.967514\n",
      "Epoch: 4, Loss: 10.824282\n",
      "Epoch: 5, Loss: 9.824005\n",
      "Epoch: 6, Loss: 8.943735\n",
      "Epoch: 7, Loss: 8.150802\n",
      "Epoch: 8, Loss: 7.432696\n",
      "Epoch: 9, Loss: 6.772128\n",
      "Epoch: 10, Loss: 6.170878\n",
      "Epoch: 11, Loss: 5.608293\n",
      "Epoch: 12, Loss: 5.101055\n",
      "Epoch: 13, Loss: 4.635466\n",
      "Epoch: 14, Loss: 4.211432\n",
      "Epoch: 15, Loss: 3.826729\n",
      "Epoch: 16, Loss: 3.477084\n",
      "Epoch: 17, Loss: 3.149423\n",
      "Epoch: 18, Loss: 2.843818\n",
      "Epoch: 19, Loss: 2.578604\n",
      "Epoch: 20, Loss: 2.328983\n",
      "Epoch: 21, Loss: 2.114716\n",
      "Epoch: 22, Loss: 1.918346\n",
      "Epoch: 23, Loss: 1.741935\n",
      "Epoch: 24, Loss: 1.584439\n",
      "Epoch: 25, Loss: 1.436309\n",
      "Epoch: 26, Loss: 1.311655\n",
      "Epoch: 27, Loss: 1.199223\n",
      "Epoch: 28, Loss: 1.103445\n",
      "Epoch: 29, Loss: 1.016246\n",
      "Epoch: 30, Loss: 0.939532\n",
      "Epoch: 31, Loss: 0.865192\n",
      "Epoch: 32, Loss: 0.808335\n",
      "Epoch: 33, Loss: 0.753397\n",
      "Epoch: 34, Loss: 0.712155\n",
      "Epoch: 35, Loss: 0.670848\n",
      "Epoch: 36, Loss: 0.634056\n",
      "Epoch: 37, Loss: 0.603389\n",
      "Epoch: 38, Loss: 0.579575\n",
      "Epoch: 39, Loss: 0.559889\n",
      "Epoch: 40, Loss: 0.543827\n",
      "Epoch: 41, Loss: 0.527126\n",
      "Epoch: 42, Loss: 0.510495\n",
      "Epoch: 43, Loss: 0.499656\n",
      "Epoch: 44, Loss: 0.488337\n",
      "Epoch: 45, Loss: 0.481544\n",
      "Epoch: 46, Loss: 0.474695\n",
      "Epoch: 47, Loss: 0.473499\n",
      "Epoch: 48, Loss: 0.466303\n",
      "Epoch: 49, Loss: 0.459077\n",
      "Epoch: 50, Loss: 0.458488\n",
      "Epoch: 51, Loss: 0.455676\n",
      "Epoch: 52, Loss: 0.449326\n",
      "Epoch: 53, Loss: 0.448375\n",
      "Epoch: 54, Loss: 0.448324\n",
      "Epoch: 55, Loss: 0.443323\n",
      "Epoch: 56, Loss: 0.443370\n",
      "Epoch: 57, Loss: 0.441635\n",
      "Epoch: 58, Loss: 0.438522\n",
      "Epoch: 59, Loss: 0.438920\n",
      "Epoch: 60, Loss: 0.437433\n",
      "Epoch: 61, Loss: 0.434497\n",
      "Epoch: 62, Loss: 0.435113\n",
      "Epoch: 63, Loss: 0.434620\n",
      "Epoch: 64, Loss: 0.431664\n",
      "Epoch: 65, Loss: 0.431759\n",
      "Epoch: 66, Loss: 0.429267\n",
      "Epoch: 67, Loss: 0.432499\n",
      "Epoch: 68, Loss: 0.429691\n",
      "Epoch: 69, Loss: 0.428044\n",
      "Epoch: 70, Loss: 0.432417\n",
      "Epoch: 71, Loss: 0.426596\n",
      "Epoch: 72, Loss: 0.425882\n",
      "Epoch: 73, Loss: 0.426347\n",
      "Epoch: 74, Loss: 0.424589\n",
      "Epoch: 75, Loss: 0.423781\n",
      "Epoch: 76, Loss: 0.422304\n",
      "Epoch: 77, Loss: 0.419736\n",
      "Epoch: 78, Loss: 0.418427\n",
      "Epoch: 79, Loss: 0.418426\n",
      "Epoch: 80, Loss: 0.416061\n",
      "Epoch: 81, Loss: 0.415865\n",
      "Epoch: 82, Loss: 0.417010\n",
      "Epoch: 83, Loss: 0.417417\n",
      "Epoch: 84, Loss: 0.416687\n",
      "Epoch: 85, Loss: 0.416549\n",
      "Epoch: 86, Loss: 0.414918\n",
      "Epoch: 87, Loss: 0.409865\n",
      "Epoch: 88, Loss: 0.408093\n",
      "Epoch: 89, Loss: 0.409333\n",
      "Epoch: 90, Loss: 0.410621\n",
      "Epoch: 91, Loss: 0.409413\n",
      "Epoch: 92, Loss: 0.409502\n",
      "Epoch: 93, Loss: 0.407321\n",
      "Epoch: 94, Loss: 0.410445\n",
      "Epoch: 95, Loss: 0.407118\n",
      "Epoch: 96, Loss: 0.407508\n",
      "Epoch: 97, Loss: 0.407834\n",
      "Epoch: 98, Loss: 0.405242\n",
      "Epoch: 99, Loss: 0.405342\n",
      "Directory './Results/emnist_balanced_letters/AE/100_Eps_ld_10_out_10_bs_1024_lr_0.0005_sil_lambda_0.02_entr_lambda_0.02/Weigths' already exists.\n"
     ]
    }
   ],
   "source": [
    "if(pretrain):\n",
    "    autoencoder.pretrain_autoencoder()\n",
    "    autoencoder.save_pretrained_weights()\n",
    "else:\n",
    "    model_save_path = autoencoder.data_dir_path + '/Weigths/autoencoder_weights.pth'\n",
    "    autoencoder.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the clustering layer using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.53\n"
     ]
    }
   ],
   "source": [
    "n_inits = 100\n",
    "if kmeans_initialization: autoencoder.kmeans_initialization(n_inits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "aborted",
     "timestamp": 1690896732869,
     "user": {
      "displayName": "ΙΩΑΝΝΗΣ ΠΑΠΑΚΩΣΤΑΣ",
      "userId": "05054721977669331577"
     },
     "user_tz": -180
    },
    "id": "GVXfROTxGNJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0 Rec L: 0.4449 Cl L: 0.5688 Entropy: 1.8479 SSil: -0.4386 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.62 ARI: 0.52\n",
      "Ep: 1 Rec L: 0.4006 Cl L: 0.5759 Entropy: 1.8219 SSil: -0.7961 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.53\n",
      "Ep: 2 Rec L: 0.4006 Cl L: 0.5802 Entropy: 1.8025 SSil: -1.0108 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.53\n",
      "Ep: 3 Rec L: 0.4075 Cl L: 0.5822 Entropy: 1.7927 SSil: -1.1090 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.52\n",
      "Ep: 4 Rec L: 0.4047 Cl L: 0.5839 Entropy: 1.7837 SSil: -1.1966 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.52\n",
      "Ep: 5 Rec L: 0.4077 Cl L: 0.5850 Entropy: 1.7777 SSil: -1.2521 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.52\n",
      "Ep: 6 Rec L: 0.4068 Cl L: 0.5858 Entropy: 1.7750 SSil: -1.2878 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.52\n",
      "Ep: 7 Rec L: 0.4094 Cl L: 0.5867 Entropy: 1.7712 SSil: -1.3335 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.51\n",
      "Ep: 8 Rec L: 0.4081 Cl L: 0.5875 Entropy: 1.7689 SSil: -1.3726 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.51\n",
      "Ep: 9 Rec L: 0.4018 Cl L: 0.5888 Entropy: 1.7612 SSil: -1.4385 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.51\n",
      "Ep: 10 Rec L: 0.4044 Cl L: 0.5897 Entropy: 1.7574 SSil: -1.4862 SIL: 0.0000 ACC: 0.70 PUR: 0.70 NMI: 0.63 ARI: 0.51\n"
     ]
    }
   ],
   "source": [
    "autoencoder.set_training_variables(n_epochs=20, lr=5e-4, sil_lambda=0.02, entr_lambda=0.02)\n",
    "latent_data, labels, clustering = autoencoder.train_autoencoder()\n",
    "cluster_centers = autoencoder.get_cluster_centers().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.plot_tsne(latent_data, labels, clustering, cluster_centers, autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.plot(latent_data, labels, clustering, cluster_centers, autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_Functions().save_excel(autoencoder.data_dir_path, autoencoder.df_eval)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "121w-F_LopS2b6ATyJPxh0a_i4mceFfzN",
     "timestamp": 1688385039773
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
