{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.special import expit\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from datasets.datasets import get_MNIST_subset_dataloader\n",
    "from typing import Optional\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10 # 10\n",
    "batch_size = 256\n",
    "data_per_pattern = 2000\n",
    "latent_dim = 50\n",
    "create_subset = True\n",
    "dataloader = get_MNIST_subset_dataloader(batch_size=batch_size, create_subset=create_subset, data_per_pattern=data_per_pattern)\n",
    "N = len(dataloader) * batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = 500 # 500\n",
    "h2 = 500 # 500\n",
    "h3 = 2000 # 2000\n",
    "latent_dim = 10\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, data_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder Model\n",
    "        self.encoder_model = nn.Sequential(\n",
    "            nn.Linear(data_shape, h1, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(h1),\n",
    "            \n",
    "            nn.Linear(h1, h2, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(h2),\n",
    "            \n",
    "            nn.Linear(h2, h3, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(h3),\n",
    "            \n",
    "            nn.Linear(h3, latent_dim, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "        )\n",
    "        \n",
    "        # Clustering MLP\n",
    "        self.cluster_MLP = nn.Sequential(\n",
    "            nn.Linear(latent_dim, n_clusters, bias=True),\n",
    "            #nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(n_clusters)\n",
    "        )\n",
    "        \n",
    "        # Decoder Model\n",
    "        self.decoder_model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, h3, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(h3),\n",
    "            \n",
    "            nn.Linear(h3, h2, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(h2),\n",
    "            \n",
    "            nn.Linear(h2, h1, bias=True),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(h1),\n",
    "            \n",
    "            nn.Linear(h1, data_shape, bias=True),\n",
    "            #nn.ReLU(inplace=True)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "        self.cluster_MLP_params = self.cluster_MLP[0].parameters()\n",
    "        self.cluster_MLP_batchNorm = self.cluster_MLP[1].parameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_model(x)\n",
    "        x = self.decoder_model(x)\n",
    "        return x\n",
    "\n",
    "    def forward_softMax(self, x):\n",
    "        x = self.encoder_model(x)\n",
    "        x = self.cluster_MLP(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = self.encoder_model(x)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = self.decoder_model(x)\n",
    "        return x\n",
    "\n",
    "data_shape = 784\n",
    "autoencoder = Autoencoder(data_shape)\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f6dfdcdbbf8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.cluster_MLP_batchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f6df2d14150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.cluster_MLP[0].parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_silhouette(X, soft_clustering, requires_distance_grad=False):\n",
    "    # No grads at distances\n",
    "    if requires_distance_grad: X = X.detach()\n",
    "    distances = torch.cdist(X, X, p=2)\n",
    "    alphas = torch.matmul(distances, soft_clustering).to(device)\n",
    "    n_data, n_clusters = alphas.shape\n",
    "    betas = torch.empty(alphas.shape).to(device)\n",
    "    \n",
    "    for i in range(n_data):\n",
    "        for j in range(n_clusters):\n",
    "            betas[i][j] = min([alphas[i][x] for x in range(alphas.shape[1]) if x!=j])\n",
    "    \n",
    "    # Calculate soft silhouette\n",
    "    sc = torch.div(torch.sub(betas, alphas), torch.max(alphas, betas))\n",
    "    s = torch.mean(torch.sum(torch.mul(soft_clustering, sc), dim=1))\n",
    "\n",
    "    return s\n",
    "\n",
    "def predictions(clusters):\n",
    "    clusters = torch.argmax(clusters, dim=1)\n",
    "    clusters = clusters.cpu().detach().numpy()\n",
    "    return clusters\n",
    "\n",
    "def transform_clusters_to_labels(clusters, labels):\n",
    "    # Get the data clusters based on max neuron\n",
    "    #clusters = torch.argmax(clusters, dim=1)\n",
    "    #clusters = clusters.cpu().detach().numpy()\n",
    "\n",
    "    # Find the cluster ids (labels)\n",
    "    c_ids = np.unique(clusters)\n",
    "    #labels = labels.cpu().data.numpy()\n",
    "\n",
    "    # Dictionary to transform cluster label to real label\n",
    "    dict_clusters_to_labels = dict()\n",
    "    \n",
    "    # For every cluster find the most frequent data label\n",
    "    for c_id in c_ids:\n",
    "        indexes_of_cluster_i = np.where(c_id == clusters)\n",
    "        elements, frequency = np.unique(labels[indexes_of_cluster_i], return_counts=True)\n",
    "        true_label_index = np.argmax(frequency)\n",
    "        true_label = elements[true_label_index]\n",
    "        dict_clusters_to_labels[c_id] = true_label\n",
    "\n",
    "    # Change the cluster labels to real labels\n",
    "    for i, element in enumerate(clusters):\n",
    "        clusters[i] = dict_clusters_to_labels[element]\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def cluster_accuracy(y_true, y_predicted, cluster_number: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy after using the linear_sum_assignment function in SciPy to\n",
    "    determine reassignments.\n",
    "\n",
    "    :param y_true: list of true cluster numbers, an integer array 0-indexed\n",
    "    :param y_predicted: list of predicted cluster numbers, an integer array 0-indexed\n",
    "    :param cluster_number: number of clusters, if None then calculated from input\n",
    "    :return: reassignment dictionary, clustering accuracy\n",
    "    \"\"\"\n",
    "    if cluster_number is None:\n",
    "        # assume labels are 0-indexed\n",
    "        cluster_number = (max(y_predicted.max(), y_true.max()) + 1)\n",
    "    count_matrix = np.zeros((cluster_number, cluster_number), dtype=np.int64)\n",
    "    for i in range(y_predicted.size):\n",
    "        count_matrix[y_predicted[i], y_true[i]] += 1\n",
    "\n",
    "    row_ind, col_ind = linear_assignment(count_matrix.max() - count_matrix)\n",
    "    reassignment = dict(zip(row_ind, col_ind))\n",
    "    accuracy = count_matrix[row_ind, col_ind].sum() / y_predicted.size\n",
    "    return reassignment, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Rec: 117.7356 \n",
      "Epoch: 1 Rec: 76.8611 \n",
      "Epoch: 2 Rec: 72.6392 \n",
      "Epoch: 3 Rec: 71.3657 \n",
      "Epoch: 4 Rec: 70.4825 \n",
      "Epoch: 5 Rec: 69.7092 \n",
      "Epoch: 6 Rec: 69.3948 \n",
      "Epoch: 7 Rec: 69.2028 \n",
      "Epoch: 8 Rec: 69.0455 \n",
      "Epoch: 9 Rec: 68.9155 \n",
      "Epoch: 10 Rec: 68.8077 \n",
      "Epoch: 11 Rec: 68.7217 \n",
      "Epoch: 12 Rec: 68.6608 \n",
      "Epoch: 13 Rec: 68.5685 \n",
      "Epoch: 14 Rec: 68.3989 \n",
      "Epoch: 15 Rec: 68.2935 \n",
      "Epoch: 16 Rec: 68.2135 \n",
      "Epoch: 17 Rec: 68.1410 \n",
      "Epoch: 18 Rec: 68.0939 \n",
      "Epoch: 19 Rec: 68.0548 \n",
      "Epoch: 20 Rec: 67.9611 \n",
      "Epoch: 21 Rec: 67.8714 \n",
      "Epoch: 22 Rec: 67.7983 \n",
      "Epoch: 23 Rec: 67.7405 \n",
      "Epoch: 24 Rec: 67.6951 \n",
      "Epoch: 25 Rec: 67.6616 \n",
      "Epoch: 26 Rec: 67.6474 \n",
      "Epoch: 27 Rec: 67.6599 \n",
      "Epoch: 28 Rec: 67.6840 \n",
      "Epoch: 29 Rec: 67.6600 \n",
      "Epoch: 30 Rec: 67.6263 \n",
      "Epoch: 31 Rec: 67.6047 \n",
      "Epoch: 32 Rec: 67.5858 \n",
      "Epoch: 33 Rec: 67.5495 \n",
      "Epoch: 34 Rec: 67.5020 \n",
      "Epoch: 35 Rec: 67.4568 \n",
      "Epoch: 36 Rec: 67.4175 \n",
      "Epoch: 37 Rec: 67.3851 \n",
      "Epoch: 38 Rec: 67.3594 \n",
      "Epoch: 39 Rec: 67.3389 \n",
      "Epoch: 40 Rec: 67.3224 \n",
      "Epoch: 41 Rec: 67.3090 \n",
      "Epoch: 42 Rec: 67.2989 \n",
      "Epoch: 43 Rec: 67.2938 \n",
      "Epoch: 44 Rec: 67.3006 \n",
      "Epoch: 45 Rec: 67.3506 \n",
      "Epoch: 46 Rec: 67.4448 \n",
      "Epoch: 47 Rec: 67.4241 \n",
      "Epoch: 48 Rec: 67.3775 \n",
      "Epoch: 49 Rec: 67.3368 \n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "latent_data = np.zeros((N, latent_dim))\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_rec_loss = 0\n",
    "    for batch_index, (real_data, labels) in enumerate(dataloader):\n",
    "        real_data = real_data.to(device)\n",
    "        real_data = torch.reshape(real_data, (real_data.shape[0], 784))\n",
    "        reconstruction = autoencoder.forward(real_data)\n",
    "        loss = mse(real_data, reconstruction)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_rec_loss += loss.item()\n",
    "        \n",
    "        # Selecting the nearest samples and save their priors\n",
    "        code = autoencoder.encoder(real_data).to(device)\n",
    "        lower = batch_index * batch_size\n",
    "        upper = (batch_index + 1) * batch_size\n",
    "        latent_data[lower:upper] = code.cpu().detach().numpy()\n",
    "    \n",
    "    print(\"Epoch: {} Rec: {:.4f} \".format(epoch, total_rec_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "kmeans = kmeans.fit(latent_data)\n",
    "kmeans_centers_init = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 10), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_centers_init.shape, autoencoder.cluster_MLP[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans_centers_init.shape\n",
    "if cuda:\n",
    "    dtype = torch.float32\n",
    "else:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "\n",
    "autoencoder.cluster_MLP[0].weight = nn.Parameter(torch.tensor(kmeans_centers_init, dtype=dtype, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 L: 70.5746 Rec: 68.6331 Soft SIL: 1.94 CL_ACC: 0.53 GR_ACC: 0.57 NMI: 0.47 \n",
      "Epoch: 1 L: 80.3157 Rec: 69.3040 Soft SIL: 11.01 CL_ACC: 0.54 GR_ACC: 0.57 NMI: 0.49 \n",
      "Epoch: 2 L: 88.8827 Rec: 69.5332 Soft SIL: 19.35 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 3 L: 96.1220 Rec: 69.6209 Soft SIL: 26.50 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 4 L: 102.6905 Rec: 69.6225 Soft SIL: 33.07 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 5 L: 108.4342 Rec: 69.6221 Soft SIL: 38.81 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 6 L: 113.8037 Rec: 69.5913 Soft SIL: 44.21 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 7 L: 117.8637 Rec: 69.5435 Soft SIL: 48.32 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 8 L: 120.8337 Rec: 69.4712 Soft SIL: 51.36 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.52 \n",
      "Epoch: 9 L: 123.0357 Rec: 69.3955 Soft SIL: 53.64 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.51 \n",
      "Epoch: 10 L: 123.3449 Rec: 69.3278 Soft SIL: 54.02 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.51 \n",
      "Epoch: 11 L: 124.1804 Rec: 69.2647 Soft SIL: 54.92 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.51 \n",
      "Epoch: 12 L: 124.5822 Rec: 69.2272 Soft SIL: 55.35 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.51 \n",
      "Epoch: 13 L: 124.9928 Rec: 69.1662 Soft SIL: 55.83 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.51 \n",
      "Epoch: 14 L: 125.0260 Rec: 69.1034 Soft SIL: 55.92 CL_ACC: 0.56 GR_ACC: 0.58 NMI: 0.51 \n",
      "Epoch: 15 L: 122.9225 Rec: 69.2047 Soft SIL: 53.72 CL_ACC: 0.55 GR_ACC: 0.57 NMI: 0.50 \n",
      "Epoch: 16 L: 117.6910 Rec: 69.5805 Soft SIL: 48.11 CL_ACC: 0.51 GR_ACC: 0.52 NMI: 0.45 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-412b85769f7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msoft_clustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_softMax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_silhouette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_clustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_distance_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-041a46f40aca>\u001b[0m in \u001b[0;36msoft_silhouette\u001b[0;34m(X, soft_clustering, requires_distance_grad)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Calculate soft silhouette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lamda = 1\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "latent_data = np.zeros((N, latent_dim))\n",
    "real_labels = np.zeros((N), dtype=np.int32)\n",
    "predicted_labels = np.zeros((N), dtype=np.int32)\n",
    "\n",
    "for epoch in range(20):\n",
    "    sum_rec_loss = 0\n",
    "    sum_soft_sihouette = 0\n",
    "    for batch_index, (real_data, labels) in enumerate(dataloader):\n",
    "        real_data = real_data.to(device)\n",
    "        real_data = torch.reshape(real_data, (real_data.shape[0], 784))\n",
    "        reconstruction = autoencoder.forward(real_data)\n",
    "        soft_clustering = autoencoder.forward_softMax(real_data).to(device)\n",
    "        code = autoencoder.encoder(real_data).to(device)\n",
    "        s = soft_silhouette(code, soft_clustering, requires_distance_grad=True)\n",
    "    \n",
    "        rec = mse(reconstruction, real_data)\n",
    "        loss = 1 - s + lamda * rec\n",
    "        \n",
    "        sum_rec_loss += rec.item()\n",
    "        sum_soft_sihouette += s.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Selecting the nearest samples and save their priors\n",
    "        lower = batch_index * batch_size\n",
    "        upper = (batch_index + 1) * batch_size\n",
    "        latent_data[lower:upper] = code.cpu().detach().numpy()\n",
    "        real_labels[lower:upper] = labels.cpu().data.numpy()\n",
    "        predicted_labels[lower:upper] = predictions(soft_clustering) \n",
    "    \n",
    "    cl_accuracy = cluster_accuracy(real_labels, predicted_labels)[1]\n",
    "    gr_accuracy = accuracy_score(transform_clusters_to_labels(predicted_labels, real_labels), real_labels)\n",
    "    nmi = normalized_mutual_info_score(real_labels, predicted_labels)\n",
    "    total_loss = sum_rec_loss + sum_soft_sihouette\n",
    "    print(\"Epoch: {} L: {:.4f} Rec: {:.4f} Soft SIL: {:.2f} CL_ACC: {:.2f} GR_ACC: {:.2f} NMI: {:.2f} \".format(epoch, total_loss, sum_rec_loss, sum_soft_sihouette, cl_accuracy, gr_accuracy, nmi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster with TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=300)\n",
    "tsne_enc = tsne.fit_transform(latent_data)\n",
    "#tsne_enc = tsne.fit_transform(real_data)\n",
    "\n",
    "# Color and marker for each true class\n",
    "colors = cm.rainbow(np.linspace(0, 1, n_clusters))\n",
    "markers = matplotlib.markers.MarkerStyle.filled_markers\n",
    "\n",
    "# Save TSNE figure to file\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "for iclass in range(0, n_clusters):\n",
    "    # Get indices for each class\n",
    "    idxs = real_labels==iclass\n",
    "    # Scatter those points in tsne dims\n",
    "    ax.scatter(tsne_enc[idxs, 0], tsne_enc[idxs, 1],\n",
    "               marker=markers[iclass], c=colors[iclass].reshape(1,-1),\n",
    "               edgecolor=None, label=r'$%i$'%iclass)\n",
    "    \n",
    "figname=\"Wine Soft Silhouette\"\n",
    "ax.set_title(figname, fontsize=24)\n",
    "ax.set_xlabel(\"$x_{1}$\", fontsize=20)\n",
    "ax.set_ylabel(\"$x_{2}$\", fontsize=20)\n",
    "plt.legend(title=\"Class\", loc='best', numpoints=1, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig(figname, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.cluster_MLP[0].out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.cluster_MLP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.cluster_MLP[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
