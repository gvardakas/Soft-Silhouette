{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2d70d3",
   "metadata": {},
   "source": [
    "###  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ce3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from Datasets.Datasets_Functions import *\n",
    "from Visualization import Visualization\n",
    "\n",
    "from Related_Codes.IDECAutoencoder import IDECAutoencoder, IDECCDAutoencoder\n",
    "from General_Functions import General_Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed866a",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6287da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = './'\n",
    "sys.path.append(path_to_module)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e36f69",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da62ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = Visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc03413",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c7919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_Shape is: 1\n",
      "Batches Number is: 110\n",
      "[10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"emnist_balanced_letters_A_J\" # The available datasets are: emnist_balanced_digits, emnist_mnist, emnist_balanced_letters_A_J, emnist_balanced_letters_K_T, emnist_balanced_letters_U_Z, har, pendigits, waveform_v1, synthetic\n",
    "module_name = \"Datasets.Datasets\"\n",
    "batch_size = 256\n",
    "n_clusters = 10\n",
    "dataloader, input_dim, data_np, labels = function_get_dataset(dataset_name, module_name, batch_size, n_clusters)\n",
    "print('Data_Shape is:', input_dim)\n",
    "print('Batches Number is:', len(dataloader))\n",
    "print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91b757",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f1ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set latent dimension and negative slope\n",
    "latent_dim = 10\n",
    "negative_slope = 0\n",
    "\n",
    "# Set pre-training epochs and learning rate\n",
    "n_pret_epochs = 100\n",
    "pret_lr = 1e-3\n",
    "\n",
    "# Set alpha, momentum, gamma, training epochs and learning rate\n",
    "alpha = 1.0\n",
    "momentum = 0.9\n",
    "gamma = 0.1\n",
    "n_epochs = 100\n",
    "lr = 5e-4\n",
    "\n",
    "# Set use_pretrain and is_mlp_ae\n",
    "use_pretrain = True\n",
    "is_mlp_ae = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5cede0",
   "metadata": {},
   "source": [
    "### Create Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ce7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(is_mlp_ae):\n",
    "    idec_autoencoder = IDECAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim , negative_slope=negative_slope)\n",
    "else:  \n",
    "    input_dim = 1\n",
    "    idec_autoencoder = IDECCDAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, negative_slope=negative_slope) \n",
    "idec_autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "idec_autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "idec_autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, momentum=momentum, alpha=alpha, gamma=gamma)\n",
    "idec_autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "idec_autoencoder.set_path()\n",
    "idec_autoencoder = idec_autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c283d9f",
   "metadata": {},
   "source": [
    "### Pretrain Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7c83b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 14.654978\n",
      "Epoch: 1, Loss: 6.306714\n",
      "Epoch: 2, Loss: 4.648780\n",
      "Epoch: 3, Loss: 3.902864\n",
      "Epoch: 4, Loss: 3.516965\n",
      "Epoch: 5, Loss: 3.273267\n",
      "Epoch: 6, Loss: 3.101950\n",
      "Epoch: 7, Loss: 2.953062\n",
      "Epoch: 8, Loss: 2.832125\n",
      "Epoch: 9, Loss: 2.744569\n",
      "Epoch: 10, Loss: 2.673469\n",
      "Epoch: 11, Loss: 2.582670\n",
      "Epoch: 12, Loss: 2.520216\n",
      "Epoch: 13, Loss: 2.477683\n",
      "Epoch: 14, Loss: 2.418638\n",
      "Epoch: 15, Loss: 2.376636\n",
      "Epoch: 16, Loss: 2.363553\n",
      "Epoch: 17, Loss: 2.313520\n",
      "Epoch: 18, Loss: 2.299832\n",
      "Epoch: 19, Loss: 2.247874\n",
      "Epoch: 20, Loss: 2.220919\n",
      "Epoch: 21, Loss: 2.186193\n",
      "Epoch: 22, Loss: 2.167298\n",
      "Epoch: 23, Loss: 2.151444\n",
      "Epoch: 24, Loss: 2.105300\n",
      "Epoch: 25, Loss: 2.100503\n",
      "Epoch: 26, Loss: 2.071942\n",
      "Epoch: 27, Loss: 2.056818\n",
      "Epoch: 28, Loss: 2.040929\n",
      "Epoch: 29, Loss: 2.025623\n",
      "Epoch: 30, Loss: 2.026499\n",
      "Epoch: 31, Loss: 2.013193\n",
      "Epoch: 32, Loss: 1.984899\n",
      "Epoch: 33, Loss: 1.965605\n",
      "Epoch: 34, Loss: 1.972945\n",
      "Epoch: 35, Loss: 1.943379\n",
      "Epoch: 36, Loss: 1.926334\n",
      "Epoch: 37, Loss: 1.914158\n",
      "Epoch: 38, Loss: 1.913749\n",
      "Epoch: 39, Loss: 1.904123\n",
      "Epoch: 40, Loss: 1.890561\n",
      "Epoch: 41, Loss: 1.891383\n",
      "Epoch: 42, Loss: 1.874761\n",
      "Epoch: 43, Loss: 1.864043\n",
      "Epoch: 44, Loss: 1.850427\n",
      "Epoch: 45, Loss: 1.840953\n",
      "Epoch: 46, Loss: 1.839726\n",
      "Epoch: 47, Loss: 1.823988\n",
      "Epoch: 48, Loss: 1.817181\n",
      "Epoch: 49, Loss: 1.824033\n",
      "Epoch: 50, Loss: 1.809154\n",
      "Epoch: 51, Loss: 1.825679\n",
      "Epoch: 52, Loss: 1.815433\n",
      "Epoch: 53, Loss: 1.805015\n",
      "Epoch: 54, Loss: 1.782402\n",
      "Epoch: 55, Loss: 1.782610\n",
      "Epoch: 56, Loss: 1.771208\n",
      "Epoch: 57, Loss: 1.762512\n",
      "Epoch: 58, Loss: 1.762263\n",
      "Epoch: 59, Loss: 1.753852\n",
      "Epoch: 60, Loss: 1.749384\n",
      "Epoch: 61, Loss: 1.742554\n",
      "Epoch: 62, Loss: 1.751533\n",
      "Epoch: 63, Loss: 1.729700\n",
      "Epoch: 64, Loss: 1.725064\n",
      "Epoch: 65, Loss: 1.753855\n",
      "Epoch: 66, Loss: 1.720678\n",
      "Epoch: 67, Loss: 1.718431\n",
      "Epoch: 68, Loss: 1.704576\n",
      "Epoch: 69, Loss: 1.721248\n",
      "Epoch: 70, Loss: 1.729145\n",
      "Epoch: 71, Loss: 1.703600\n",
      "Epoch: 72, Loss: 1.693449\n",
      "Epoch: 73, Loss: 1.706076\n",
      "Epoch: 74, Loss: 1.698824\n",
      "Epoch: 75, Loss: 1.676914\n",
      "Epoch: 76, Loss: 1.672544\n",
      "Epoch: 77, Loss: 1.696478\n",
      "Epoch: 78, Loss: 1.668046\n",
      "Epoch: 79, Loss: 1.680971\n",
      "Epoch: 80, Loss: 1.683751\n",
      "Epoch: 81, Loss: 1.661558\n",
      "Epoch: 82, Loss: 1.660890\n",
      "Epoch: 83, Loss: 1.676134\n",
      "Epoch: 84, Loss: 1.663752\n",
      "Epoch: 85, Loss: 1.661923\n",
      "Epoch: 86, Loss: 1.647290\n",
      "Epoch: 87, Loss: 1.647790\n",
      "Epoch: 88, Loss: 1.656052\n",
      "Epoch: 89, Loss: 1.647402\n",
      "Epoch: 90, Loss: 1.634575\n",
      "Epoch: 91, Loss: 1.635711\n",
      "Epoch: 92, Loss: 1.657659\n",
      "Epoch: 93, Loss: 1.643627\n",
      "Epoch: 94, Loss: 1.635821\n",
      "Epoch: 95, Loss: 1.645739\n",
      "Epoch: 96, Loss: 1.643677\n",
      "Epoch: 97, Loss: 1.614746\n"
     ]
    }
   ],
   "source": [
    "if(use_pretrain):\n",
    "    idec_autoencoder.pretrain_autoencoder()\n",
    "    idec_autoencoder.save_pretrained_weights()\n",
    "else:\n",
    "    model_save_path = idec_autoencoder.data_dir_path + '/Weigths/autoencoder_weights.pth'\n",
    "    idec_autoencoder.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fef0d",
   "metadata": {},
   "source": [
    "### Initialize the clustering layer using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f47ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idec_autoencoder.kmeans_initialization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a673b",
   "metadata": {},
   "source": [
    "### Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "idec_autoencoder.train_autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5689cb5",
   "metadata": {},
   "source": [
    "### Save Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "General_Functions().save_excel(idec_autoencoder.data_dir_path, idec_autoencoder.df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0cbee",
   "metadata": {},
   "source": [
    "### Plot Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = idec_autoencoder.get_cluster_centers()\n",
    "_, idec_autoencoder_reduced_data, labels = idec_autoencoder.get_latent_data()\n",
    "visualization.plot_tsne(idec_autoencoder_reduced_data, labels, labels, cluster_centers, idec_autoencoder.data_dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
