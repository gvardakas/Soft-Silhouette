{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0037f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "from torchvision.transforms.functional import InterpolationMode \n",
    "def plot_image(image, label):\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  \n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def reshape_olivetti_faces(images, new_shape=(28, 28)):\n",
    "    num_samples, original_height, original_width = images.shape\n",
    "    reshaped_images = np.empty((num_samples, *new_shape))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        reshaped_images[i] = np.reshape(images[i], (28,28))\n",
    "    \n",
    "    return reshaped_images\n",
    "\n",
    "def get_olivetti_faces_dataloader(batch_size=64, drop_last=True, shuffle=True):\n",
    "    \n",
    "    faces_data = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
    "\n",
    "    # Load your images as a NumPy array\n",
    "    # Replace 'images_array' with your actual NumPy array\n",
    "    olivetti_faces = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
    "    images_array = olivetti_faces.images\n",
    "    labels = olivetti_faces.target\n",
    "    \n",
    "    # Define the target size (28x28)\n",
    "    target_size = (28, 28)\n",
    "\n",
    "    # Initialize an empty list to store resized images\n",
    "    resized_images = []\n",
    "\n",
    "    # Define the Resize transformation to resize the images\n",
    "    resize_transform = transforms.Resize(target_size, interpolation=InterpolationMode.NEAREST)\n",
    "\n",
    "    # Loop through each image in the array\n",
    "    for image_data in images_array:\n",
    "        # Convert the image data to a PIL image\n",
    "        original_image = Image.fromarray(np.uint8(image_data * 255))  # Assuming the data is in the range [0, 1]\n",
    "\n",
    "        # Apply the Resize transformation\n",
    "        resized_image = resize_transform(original_image)\n",
    "\n",
    "        # Convert the resized image back to a NumPy array\n",
    "        resized_image_array = np.array(resized_image) / 255.0  # Rescale back to [0, 1]\n",
    "\n",
    "        # Append the resized image to the list\n",
    "        resized_images.append(resized_image_array)\n",
    "    \n",
    "    # Stack the resized images into a NumPy array\n",
    "    resized_images_array = np.stack(resized_images)\n",
    "\n",
    "    \n",
    "    \n",
    "    data = torch.Tensor(resized_images_array)\n",
    "    plot_image(data[0], labels[0])\n",
    "    data_shape = data.shape[1:]\n",
    "    labels = torch.Tensor(labels)\n",
    "    \n",
    "    \n",
    "    final_dataset = TensorDataset(data, labels)\n",
    "    \n",
    "    dataloader = DataLoader(final_dataset, batch_size=batch_size, drop_last=drop_last, shuffle=shuffle)\n",
    "    \n",
    "    return dataloader, data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848020c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6971daf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m         ax\u001b[38;5;241m.\u001b[39mremove()\n\u001b[0;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 20\u001b[0m data, similarity, similarity_to_labels, labels \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241m.\u001b[39mget_similarity_data()\n\u001b[0;32m     21\u001b[0m valid_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(similarity_to_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m7\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     22\u001b[0m min_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000000\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_faces(faces, labels, n_cols=100):\n",
    "    faces = faces.reshape(-1, 28, 28)\n",
    "    n_rows = (len(faces) - 1) // n_cols + 1\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(500,500))\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)  # Set spacing to 0\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for ax, (face, label) in zip(axes.flat, zip(faces, labels)):\n",
    "        ax.imshow(face, cmap=\"gray\")\n",
    "        #ax.set_title(label)\n",
    "\n",
    "    for ax in axes.flat[len(faces):]:\n",
    "        ax.remove()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "data, similarity, similarity_to_labels, labels = autoencoder.get_similarity_data()\n",
    "valid_indices = np.where(similarity_to_labels == 7)[0]\n",
    "min_s = 100000000\n",
    "max_s = -10000000\n",
    "\n",
    "valid_indices_2 = list()\n",
    "for index in valid_indices:\n",
    "    cur_similarity = similarity[index][similarity_to_labels[index]]\n",
    "    if(min_s > cur_similarity):\n",
    "        min_s = cur_similarity\n",
    "    if(max_s < cur_similarity):\n",
    "        max_s = cur_similarity\n",
    "    if( cur_similarity > 0.05 ):\n",
    "        valid_indices_2.append(index)\n",
    "print(min_s)\n",
    "print(max_s)\n",
    "print(valid_indices_2)        \n",
    "plot_faces(data[valid_indices_2],labels[valid_indices_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fec985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "# Define the size of each individual image\n",
    "image_size = (28, 28)\n",
    "\n",
    "# Create a blank canvas for the collage\n",
    "collage_size = (image_size[0] * 10, image_size[1] * 10)\n",
    "collage = Image.new('RGB', collage_size)\n",
    "\n",
    "# Create a drawing context to paste images onto the canvas\n",
    "draw = ImageDraw.Draw(collage)\n",
    "\n",
    "# Initialize x and y positions for pasting images\n",
    "x, y = 0, 0\n",
    "\n",
    "# Generate random colored squares as image placeholders\n",
    "for _ in range(10):\n",
    "    for _ in range(10):\n",
    "        color = tuple(np.random.randint(0, 256, 3))  # Generate a random RGB color\n",
    "        draw.rectangle([x, y, x + image_size[0], y + image_size[1]], fill=color)\n",
    "        x += image_size[0]\n",
    "    x = 0\n",
    "    y += image_size[1]\n",
    "\n",
    "# Save the collage to a file or display it\n",
    "collage.save('collage.png')  # Change the filename and format as needed\n",
    "collage.show()  # Display the collage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load the PNG image files\n",
    "image1 = Image.open('collage_digits_8_8.png')\n",
    "image2 = Image.open('collage_letters_8_8.png')\n",
    "\n",
    "# Create a figure with two subfigures (subplots)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Display the first image in the first subfigure\n",
    "axes[0].imshow(image1)\n",
    "#axes[0].set_title('Subfigure 1')\n",
    "\n",
    "# Display the second image in the second subfigure\n",
    "axes[1].imshow(image2)\n",
    "#axes[1].set_title('Subfigure 2')\n",
    "\n",
    "# Add a title to the entire figure\n",
    "#fig.suptitle('Figure with Two Subfigures')\n",
    "\n",
    "# Remove axis labels and ticks\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust spacing between subfigures\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "categories = None\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "labels = newsgroups_train.target\n",
    "\n",
    "true_k = 12\n",
    "\n",
    "#vectorize\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                             min_df=2,\n",
    "                             stop_words='english')\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "#clustering\n",
    "km = KMeans(n_clusters=20, init='k-means++', max_iter=100, n_init=1)\n",
    "\n",
    "km.fit(X)\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "\n",
    "#Performance\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the USPS dataset\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Access the data and labels\n",
    "X, y = usps.data, usps.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "class USPSDataset(Dataset):\n",
    "    def __init__(self, split='train', transform=None):\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load the USPS dataset using Scikit-Learn\n",
    "        usps = fetch_openml(name=\"usps\", version=2)\n",
    "        self.data, self.labels = usps.data, usps.target.astype(int)\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            self.data = self.data[:7291]  # Use the first 7291 samples for training\n",
    "            self.labels = self.labels[:7291]\n",
    "        elif self.split == 'test':\n",
    "            self.data = self.data[7291:]  # Use the remaining samples for testing\n",
    "            self.labels = self.labels[7291:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx].reshape(16, 16).astype('float32')  # Reshape the data to (16, 16)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations if needed (e.g., converting to tensors)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create USPS dataset instances for training and testing\n",
    "usps_train_dataset = USPSDataset(split='train', transform=transform)\n",
    "usps_test_dataset = USPSDataset(split='test', transform=transform)\n",
    "\n",
    "# Example of how to access the data and labels\n",
    "sample_image, sample_label = usps_train_dataset[0]\n",
    "print(\"Sample Image Shape:\", sample_image.shape)\n",
    "print(\"Sample Label:\", sample_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c61e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from Visualization import Visualization\n",
    "visualization = Visualization()\n",
    "def get_usps_np():\n",
    "    # Load the USPS dataset using Scikit-Learn\n",
    "    usps = fetch_openml(name=\"usps\", version=2)\n",
    "    \n",
    "    # Extract the data and labels as NumPy arrays\n",
    "    usps_data = usps.data.astype(float).to_numpy()\n",
    "    usps_labels = usps.target.astype(int).to_numpy()\n",
    "    data = np.reshape(usps_data, (-1, 1, 16, 16))\n",
    "    visualization.plot_image(data[0], usps_labels[0])\n",
    "    # Initialize an empty array for resized images\n",
    "    usps_data_resized = np.zeros((len(usps_data), 28, 28))\n",
    "    \n",
    "    # Resize each image to 28x28 pixels and store in the new array\n",
    "    for i in range(len(usps_data)):\n",
    "        # Convert the image to a Pillow Image\n",
    "        image = Image.fromarray(usps_data[i].reshape(16, 16).astype(float), 'L')\n",
    "    \n",
    "        # Resize the image to 28x28 pixels using antialiasing\n",
    "        image_resized = image.resize((28, 28), Image.BILINEAR)\n",
    "    \n",
    "        # Convert the resized image back to a NumPy array\n",
    "        usps_data_resized[i] = np.array(image_resized, dtype='float32') / 255.0\n",
    "    \n",
    "    \n",
    "    # Print the shape of the resized data\n",
    "    print(\"Resized Data Shape:\", usps_data_resized.shape)\n",
    "    \n",
    "    data = np.reshape(usps_data_resized, (-1, 1, 28, 28))\n",
    "    print(data[0].shape)\n",
    "    labels = LabelEncoder().fit_transform(usps_labels)\n",
    "    \n",
    "    visualization.plot_image(data[0], labels[0])    \n",
    "    return data, labels\n",
    "data, labels = get_usps_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7eadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the USPS dataset using Scikit-Learn\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "usps_data = usps.data.astype(float).to_numpy()\n",
    "usps_labels = usps.target.astype(int).to_numpy()\n",
    "\n",
    "# Initialize an empty array for resized images\n",
    "usps_data_resized = np.zeros((len(usps_data), 28, 28))\n",
    "\n",
    "# Resize each image to 28x28 pixels without losing quality using LANCZOS filter\n",
    "for i in range(len(usps_data)):\n",
    "    # Reshape the image to 16x16 pixels\n",
    "    image = usps_data[i].reshape(16, 16).astype('uint8')\n",
    "    \n",
    "    # Convert the image to a Pillow Image\n",
    "    image_pil = Image.fromarray(image, 'L')\n",
    "    \n",
    "    # Resize the image to 28x28 pixels without losing quality using LANCZOS filter\n",
    "    image_resized = image_pil.resize((28, 28), Image.LANCZOS)\n",
    "    \n",
    "    # Convert the resized image back to a NumPy array\n",
    "    usps_data_resized[i] = np.array(image_resized, dtype='float32') / 255.0\n",
    "\n",
    "# Plot the resized image (e.g., the first image)\n",
    "plt.figure()\n",
    "plt.imshow(usps_data_resized[0], cmap='gray')  # cmap='gray' for grayscale\n",
    "plt.title(f'USPS Label: {usps_labels[0]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92211aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the USPS dataset using Scikit-Learn\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "usps_data = usps.data.astype(float).to_numpy()\n",
    "usps_labels = usps.target.astype(int).to_numpy()\n",
    "\n",
    "# Choose an index to plot (e.g., the first image)\n",
    "index_to_plot = 0\n",
    "\n",
    "# Resize the chosen image to 28x28 pixels with BILINEAR interpolation\n",
    "chosen_image = Image.fromarray(usps_data[index_to_plot].reshape(16, 16).astype('uint8'), 'L')\n",
    "chosen_image_resized = chosen_image.resize((28, 28), Image.BILINEAR)\n",
    "\n",
    "# Convert the resized image back to a NumPy array\n",
    "resized_image = np.array(chosen_image_resized, dtype='float32') / 255.0\n",
    "\n",
    "# Plot the resized image\n",
    "plt.figure()\n",
    "plt.imshow(resized_image[0], cmap='gray')  # cmap='gray' for grayscale\n",
    "plt.title(f'USPS Label: {usps_labels[index_to_plot]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b75cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "SHUFFLE = True \n",
    "IMG_SIZE = 28\n",
    "\n",
    "folder_path = './Datasets/'\n",
    "# Options: balanced, byclass, bymerge, digits, letters, mnist\n",
    "mndata = MNIST(folder_path + 'EMNIST')\n",
    "\n",
    "mndata.select_emnist('balanced') \n",
    "data, labels = mndata.load_training()\n",
    "data_ts, labels_ts = mndata.load_testing()\n",
    "\n",
    "data = np.vstack((data, data_ts))\n",
    "labels = np.hstack((labels, labels_ts))\n",
    "data = MinMaxScaler().fit_transform(data).astype(np.float32)\n",
    "print(data[0].shape)\n",
    "data = np.reshape(data, (-1, 1, 28, 28))\n",
    "print(data[0].shape)\n",
    "labels = np.array(labels)\n",
    "labels = LabelEncoder().fit_transform(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the USPS dataset using Scikit-Learn\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "usps_data = usps.data.astype(float).to_numpy()\n",
    "usps_labels = usps.target.astype(int).to_numpy()\n",
    "\n",
    "# Reshape the USPS dataset images to 28x28 pixels\n",
    "usps_data_reshaped = usps_data.reshape(-1, 16, 16)  # Reshape from (7291, 256) to (7291, 16, 16)\n",
    "\n",
    "# Upscale the images to 28x28\n",
    "usps_data_upscaled = np.zeros((len(usps_data_reshaped), 28, 28))\n",
    "for i in range(len(usps_data_reshaped)):\n",
    "    usps_data_upscaled[i] = np.kron(usps_data_reshaped[i], np.ones((2, 2)))\n",
    "\n",
    "# Print the shapes of the data and labels\n",
    "print(\"Reshaped Data Shape:\", usps_data_upscaled.shape)\n",
    "print(\"Training Labels Shape:\", usps_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b16a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the USPS dataset using Scikit-Learn\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "usps_data = usps.data.astype(float).to_numpy()\n",
    "usps_labels = usps.target.astype(int).to_numpy()\n",
    "\n",
    "# Initialize an empty array for resized images\n",
    "usps_data_resized = np.zeros((len(usps_data), 28, 28))\n",
    "\n",
    "# Resize each image to 28x28 pixels without losing quality\n",
    "for i in range(len(usps_data)):\n",
    "    # Reshape the image to 16x16 pixels\n",
    "    image = usps_data[i].reshape(16, 16).astype('uint8')\n",
    "    \n",
    "    # Resize the image to 28x28 pixels without losing quality using INTER_LINEAR interpolation\n",
    "    image_resized = cv2.resize(image, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Convert the resized image back to a NumPy array\n",
    "    usps_data_resized[i] = image_resized.astype('float32') / 255.0\n",
    "\n",
    "# Plot the resized image (e.g., the first image)\n",
    "plt.figure()\n",
    "plt.imshow(usps_data[0], cmap='gray')  # cmap='gray' for grayscale\n",
    "plt.title(f'USPS Label: {usps_labels[0]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = usps_data[0]\n",
    "print(image)\n",
    "# Resize the image to 28x28 pixels\n",
    "image_resized = image.resize((28, 28), Image.LANCZOS)  # You can use other resampling methods as well\n",
    "\n",
    "# Convert the resized image to a NumPy array\n",
    "image_array = np.array(image_resized)\n",
    "\n",
    "# Plot the original and resized images\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Original (16x16)\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.title(\"Resized (28x28)\")\n",
    "plt.show()\n",
    "\n",
    "# Optionally, save the resized image to a file\n",
    "image_resized.save(\"resized_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the USPS dataset using Scikit-Learn\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "usps_data = usps.data.astype(float).to_numpy()\n",
    "usps_labels = usps.target.astype(int).to_numpy()\n",
    "\n",
    "usps_data = np.reshape(usps_data, (-1, 1, 16, 16))\n",
    "\n",
    "visualization.plot_image(usps_data[0], usps_labels[0])\n",
    "\n",
    "# Initialize an empty array for resized images (28x28)\n",
    "usps_data_resized = np.zeros((len(usps_data), 28, 28))\n",
    "\n",
    "# Initialize a subplot for plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "\n",
    "# Create a new 28x28 array filled with zeros\n",
    "new_array = np.zeros((28, 28))\n",
    "\n",
    "# Calculate the padding (6 pixels on each side)\n",
    "padding = (28 - 16) // 2\n",
    "\n",
    "# Copy the initial array into the center of the new array\n",
    "new_array[padding:padding + 16, padding:padding + 16] = initial_array\n",
    "\n",
    "# Loop through each image, add black borders, and resize to 28x28\n",
    "for i in range(len(usps_data)):\n",
    "\n",
    "\n",
    "    # Plot the original and resized images (sample every 500 images)\n",
    "    if i % 500 == 0:\n",
    "        axs[0].imshow(image, cmap='gray')\n",
    "        axs[0].set_title(\"Original (16x16)\")\n",
    "        axs[1].imshow(usps_data_resized[i], cmap='gray')\n",
    "        axs[1].set_title(\"Resized (28x28 with borders)\")\n",
    "        plt.show()\n",
    "\n",
    "# Print the shape of the resized data\n",
    "print(\"Resized Data Shape:\", usps_data_resized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d995f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the USPS dataset using Scikit-Learn\n",
    "usps = fetch_openml(name=\"usps\", version=2)\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "usps_data = usps.data.astype(float).to_numpy()\n",
    "usps_labels = usps.target.astype(int).to_numpy()\n",
    "\n",
    "# Initialize an empty array for resized images (28x28) with padding filled with -1\n",
    "usps_data_padded = np.full((len(usps_data), 28, 28), -1.0)\n",
    "\n",
    "# Calculate padding size (6 pixels on each side)\n",
    "padding = (28 - 16) // 2\n",
    "\n",
    "# Loop through each image and add padding with -1 values to make it 28x28\n",
    "for i in range(len(usps_data)):\n",
    "    # Reshape the image to 16x16 pixels\n",
    "    image = usps_data[i].reshape(16, 16).astype('float32')\n",
    "    \n",
    "    # Create a 28x28 canvas filled with -1 values\n",
    "    padded_image = np.full((28, 28), -1.0)\n",
    "    \n",
    "    # Paste the original image into the center of the canvas\n",
    "    padded_image[padding:padding+16, padding:padding+16] = image # Scale pixel values to 0-1\n",
    "    \n",
    "    # Store the padded image in the new array\n",
    "    usps_data_padded[i] = padded_image\n",
    "\n",
    "# Print the shape of the padded data\n",
    "print(\"Padded Data Shape:\", usps_data_padded.shape)\n",
    "\n",
    "visualization.plot_image(usps_data_padded[0], usps_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db514d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've already defined and created the DVS_Gesture_Dataset and DataLoader instances as shown in the previous response.\n",
    "\n",
    "# Load a batch of data and labels from the training DataLoader\n",
    "batch_iterator = iter(train_loader)\n",
    "sample_data, sample_labels = next(batch_iterator)\n",
    "\n",
    "# Display a sample image from the batch\n",
    "sample_image = sample_data[0].squeeze().numpy()  # Remove the batch dimension and convert to NumPy array\n",
    "sample_label = sample_labels[0]\n",
    "\n",
    "# Define a dictionary to map labels to gesture names (you may need to create this)\n",
    "label_to_gesture = {0: 'Gesture 0', 1: 'Gesture 1', 2: 'Gesture 2', ...}\n",
    "\n",
    "# Display the sample image and label\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(f'Gesture: {label_to_gesture[sample_label.item()]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ece69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x, total, unit: x  # If tqdm doesn't exist, replace it with a function that does nothing\n",
    "    print('**** Could not import tqdm. Please install tqdm for download progressbars! (pip install tqdm) ****')\n",
    "\n",
    "# Python2 compatibility\n",
    "try:\n",
    "    input = raw_input\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "download_dict = {\n",
    "    '1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)': {\n",
    "        '1) MNIST data format (ubyte.gz)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'],\n",
    "        '2) NumPy data format (.npz)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz'],\n",
    "    },\n",
    "    '2) Kuzushiji-49 (49 classes, 28x28, 270k examples)': {\n",
    "        '1) NumPy data format (.npz)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz'],\n",
    "    },\n",
    "    '3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)': {\n",
    "        '1) Folders of images (.tar)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar'],\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "# Download a list of files\n",
    "def download_list(url_list):\n",
    "    for url in url_list:\n",
    "        path = url.split('/')[-1]\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            total_length = int(r.headers.get('content-length'))\n",
    "            print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
    "\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    print('All dataset files downloaded!')\n",
    "\n",
    "# Ask the user about which path to take down the dict\n",
    "def traverse_dict(d):\n",
    "    print('Please select a download option:')\n",
    "    keys = sorted(d.keys())  # Print download options\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "\n",
    "    userinput = input('> ').strip()\n",
    "\n",
    "    try:\n",
    "        selection = int(userinput) - 1\n",
    "    except ValueError:\n",
    "        print('Your selection was not valid')\n",
    "        traverse_dict(d)  # Try again if input was not valid\n",
    "        return\n",
    "\n",
    "    selected = keys[selection]\n",
    "\n",
    "    next_level = d[selected]\n",
    "    if isinstance(next_level, list):  # If we've hit a list of downloads, download that list\n",
    "        download_list(next_level)\n",
    "    else:\n",
    "        traverse_dict(next_level)     # Otherwise, repeat with the next level\n",
    "\n",
    "traverse_dict(download_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c780ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on MNIST CNN from Keras' examples: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py (MIT License)\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "\n",
    "\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dfd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "# Load the data\n",
    "x_train = np.load('./Datasets/KMNIST/kmnist-train-imgs.npz')['arr_0']\n",
    "y_train = np.load('./Datasets/KMNIST/kmnist-train-labels.npz')['arr_0']\n",
    "x_train = x_train.reshape(-1, x_train.shape[-1])\n",
    "\n",
    "data = MinMaxScaler().fit_transform(x_train).astype(np.float32)\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "print(x_train[0])\n",
    "print('{} train samples, {} test samples'.format(len(x_train), len(x_test)))\n",
    "visualization.plot_image(x_train[0], usps_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ba7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a sample 3D NumPy array (for demonstration purposes)\n",
    "# Replace this with your actual 3D array.\n",
    "three_dim_array = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "# Get the shape of the 3D array\n",
    "original_shape = three_dim_array.shape\n",
    "\n",
    "# Reshape the 3D array to a 2D array\n",
    "# The shape of the resulting 2D array depends on your requirements.\n",
    "# Here, we're flattening it into a 2D array with one row per element.\n",
    "two_dim_array = three_dim_array.reshape(-1, original_shape[-1])\n",
    "\n",
    "# Print the original and resulting arrays for demonstration\n",
    "print(\"Original 3D Array:\")\n",
    "print(three_dim_array)\n",
    "print(\"Shape of Original 3D Array:\", original_shape)\n",
    "\n",
    "print(\"\\nReshaped 2D Array:\")\n",
    "print(two_dim_array)\n",
    "print(\"Shape of Reshaped 2D Array:\", two_dim_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath='./shrec2017_skel-data.pckl'):\n",
    "    \"\"\"\n",
    "    Returns hand gesture sequences (X) and their associated labels (Y).\n",
    "    Each sequence has two different labels.\n",
    "    The first label  Y describes the gesture class out of 14 possible gestures (e.g. swiping your hand to the right).\n",
    "    The second label Y describes the gesture class out of 28 possible gestures (e.g. swiping your hand to the right with your index pointed, or not pointed).\n",
    "    \"\"\"\n",
    "    file = open(filepath, 'rb')\n",
    "    data = pickle.load(file, encoding='latin1')  # <<---- change to 'latin1' to 'utf8' if the data does not load\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Download the Reuters dataset if you haven't already\n",
    "nltk.download('reuters')\n",
    "\n",
    "# Define the four categories or classes you want to include\n",
    "categories = ['earn', 'acq', 'crude', 'trade']\n",
    "\n",
    "# Load documents from the Reuters-4 dataset\n",
    "documents = reuters.fileids(categories=categories)\n",
    "\n",
    "# Extract the text content of the documents\n",
    "corpus = [reuters.raw(doc_id) for doc_id in documents]\n",
    "\n",
    "# Use a text vectorization technique, like TF-IDF or CountVectorizer, to convert the text into numerical features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the sparse TF-IDF matrix to a dense NumPy array\n",
    "X = X.toarray()\n",
    "\n",
    "# Now, X is a NumPy array containing numerical features for clustering\n",
    "print(X.shape)  # Shape of X: (number_of_documents, number_of_features)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CD_Autoencoder(nn.Module):\n",
    "    def __init__(self, device, n_clusters, input_channels, input_height, input_width, latent_dim, negative_slope):\n",
    "        super(CD_Autoencoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.n_clusters = n_clusters\n",
    "        self.input_channels = input_channels\n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "        self.latent_dim = latent_dim\n",
    "        self.negative_slope = negative_slope\n",
    "        self.needsReshape = True\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_model = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channels, 32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(128 * 3 * 3, self.latent_dim, bias=True),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(self.latent_dim),\n",
    "        )\n",
    "        \n",
    "        # Clustering MLP - MLP Part from latent Dimension to Number of Clusters\n",
    "        self.cluster_model = nn.Sequential(\n",
    "            # Output Layer\n",
    "            nn.Linear(self.latent_dim, self.n_clusters, bias=True),\n",
    "        )\n",
    "        \n",
    "        # Decoder \n",
    "        self.decoder_model = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 128 * 3 * 3, bias=True),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm1d(128 * 3 * 3),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(128, 3, 3)),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=0, output_padding=1),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, self.input_channels, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.LeakyReLU(negative_slope=self.negative_slope, inplace=True),\n",
    "            nn.BatchNorm2d(self.input_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through encoder\n",
    "        encoded = self.encoder_model(x)\n",
    "        \n",
    "        # Forward pass through clustering layer\n",
    "        cluster_logits = self.cluster_model(encoded)\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        decoded = self.decoder_model(encoded)\n",
    "        \n",
    "        return cluster_logits, decoded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
