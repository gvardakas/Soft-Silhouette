{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ce3775",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3428067944.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    from Related-Codes.DCNAutoencoder import DCNAutoencoder, DCNCDAutoencoder\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Related-Codes.DCNAutoencoder import DCNAutoencoder, DCNCDAutoencoder\n",
    "from Related-Codes.DECAutoencoder import DECAutoencoder, DECCDAutoencoder\n",
    "from Related-Codes.IDECAutoencoder import IDECAutoencoder, IDECCDAutoencoder\n",
    "from General_Functions import General_Functions\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, NMF\n",
    "from sklearn.manifold import LocallyLinearEmbedding, SpectralEmbedding\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from Datasets.Datasets_Functions import *\n",
    "from Visualization import Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = './'\n",
    "sys.path.append(path_to_module)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashmap_path = path_to_module + 'Datasets/'\n",
    "hashmap = get_hashmap(hashmap_path)\n",
    "print(hashmap)\n",
    "dataset_name = \"emnist_balanced_digits\"\n",
    "dataset_properties = hashmap[dataset_name]\n",
    "batch_size = dataset_properties['batch_size'] = 256\n",
    "#n_clusters = dataset_properties['n_clusters'] = 6\n",
    "dataloader, input_dim, data_np, labels = function_get_dataset(dataset_name, dataset_properties)\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91742e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = Visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08a290",
   "metadata": {},
   "source": [
    "### IDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ab512",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = dataset_properties['n_clusters']\n",
    "\n",
    "# Batch Size and Number of Clusters\n",
    "batch_size = dataset_properties['batch_size']\n",
    "\n",
    "# Pre-Training Epochs and Learning Rate\n",
    "n_pret_epochs = 100\n",
    "pret_lr = 1e-3\n",
    "\n",
    "# Lamdas, Training Epochs and Learning Rate\n",
    "n_epochs = 100\n",
    "lr = 1e-3\n",
    "alpha = 1.0\n",
    "gamma = 0.1\n",
    "momentum = 0.9\n",
    "latent_dim = 10\n",
    "n_channels = 1\n",
    "is_MLP_AE = False\n",
    "\n",
    "if(is_MLP_AE):\n",
    "    idec_autoencoder = IDECAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim)\n",
    "else:  \n",
    "    input_dim = 1\n",
    "    idec_autoencoder = IDECCDAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, n_channels=n_channels) \n",
    "idec_autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "idec_autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "idec_autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, momentum=momentum, alpha=alpha, gamma=gamma)\n",
    "idec_autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "idec_autoencoder.set_path()\n",
    "idec_autoencoder = idec_autoencoder.to(device)\n",
    "\n",
    "pretrain = True\n",
    "if(pretrain):\n",
    "    idec_autoencoder.pretrain_autoencoder()\n",
    "    idec_autoencoder.save_pretrained_weights()\n",
    "else:\n",
    "    model_save_path = idec_autoencoder.data_dir_path + '/Weigths/autoencoder_weights.pth'\n",
    "    idec_autoencoder.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idec_autoencoder.kmeans_initialization()\n",
    "idec_autoencoder.train_autoencoder()\n",
    "cluster_centers = idec_autoencoder.get_cluster_centers()\n",
    "_, idec_autoencoder_reduced_data, labels = idec_autoencoder.get_latent_data()\n",
    "General_Functions().save_excel(idec_autoencoder.data_dir_path, idec_autoencoder.df_eval)\n",
    "#visualization.plot(idec_autoencoder_reduced_data, labels, labels, cluster_centers, idec_autoencoder.data_dir_path)\n",
    "visualization.plot_tsne(idec_autoencoder_reduced_data, labels, labels, cluster_centers, idec_autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idec_autoencoder.kmeans_initializatio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d90a1",
   "metadata": {},
   "source": [
    "### Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = dataset_properties['n_clusters']\n",
    "\n",
    "# Batch Size and Number of Clusters\n",
    "batch_size = dataset_properties['batch_size']\n",
    "\n",
    "# Pre-Training Epochs and Learning Rate\n",
    "n_pret_epochs = 100\n",
    "pret_lr = 1e-3\n",
    "\n",
    "# Lamdas, Training Epochs and Learning Rate\n",
    "n_epochs = 100\n",
    "lr = 5e-4\n",
    "alpha = 1.0\n",
    "momentum = 0.9\n",
    "latent_dim = 10\n",
    "n_channels = 1\n",
    "is_MLP_AE = False\n",
    "\n",
    "if(is_MLP_AE):\n",
    "    input_dim = 784\n",
    "    dec_autoencoder = DECAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim)\n",
    "else:  \n",
    "    input_dim = 1\n",
    "    dec_autoencoder = DECCDAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, n_channels=n_channels) \n",
    "dec_autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "dec_autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "dec_autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, momentum=momentum, alpha=alpha )\n",
    "dec_autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "dec_autoencoder.set_path()\n",
    "dec_autoencoder = dec_autoencoder.to(device)\n",
    "\n",
    "pretrain = True\n",
    "if(pretrain):\n",
    "    dec_autoencoder.pretrain_autoencoder()\n",
    "    dec_autoencoder.save_pretrained_weights()\n",
    "else:\n",
    "    model_save_path = dec_autoencoder.data_dir_path + '/Weigths/autoencoder_weights.pth'\n",
    "    dec_autoencoder.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90315d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_autoencoder.kmeans_initialization()\n",
    "dec_autoencoder.train_autoencoder()\n",
    "cluster_centers = dec_autoencoder.get_cluster_centers()\n",
    "_, dec_autoencoder_reduced_data, labels = dec_autoencoder.get_latent_data()\n",
    "General_Functions().save_excel(dec_autoencoder.data_dir_path, dec_autoencoder.df_eval)\n",
    "visualization.plot(dec_autoencoder_reduced_data, labels, labels, cluster_centers, dec_autoencoder.data_dir_path)\n",
    "#visualization.plot_tsne(dec_autoencoder_reduced_data, labels, labels, cluster_centers, dec_autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_autoencoder.kmeans_initializatio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e3e04",
   "metadata": {},
   "source": [
    "### Dcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a39599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "parser.add_argument('--n-classes', type=int, default=10,\n",
    "                    help='output dimension')\n",
    "\"\"\"\n",
    "n_clusters = dataset_properties['n_clusters'] = 6\n",
    "\n",
    "# Batch Size and Number of Clusters\n",
    "batch_size = dataset_properties['batch_size'] = 256\n",
    "\n",
    "# Pre-Training Epochs and Learning Rate\n",
    "\"\"\"\n",
    "parser.add_argument('--pre-epoch', type=int, default=50, \n",
    "                    help='number of pre-train epochs')\n",
    "\"\"\"\n",
    "n_pret_epochs = 100\n",
    "pret_lr = 1e-3\n",
    "\n",
    "# Lamdas, Training Epochs and Learning Rate\n",
    "\"\"\"\n",
    "parser.add_argument('--epoch', type=int, default=100,\n",
    "                    help='number of epochs to train')\n",
    "\"\"\"\n",
    "n_epochs = 100\n",
    "\"\"\"\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate (default: 1e-4)')\n",
    "\"\"\"\n",
    "lr = 1e-4\n",
    "\"\"\"\n",
    "parser.add_argument('--lamda', type=float, default=1,\n",
    "                    help='coefficient of the reconstruction loss')\n",
    "\"\"\"\n",
    "lamda = 1\n",
    "\"\"\"\n",
    "parser.add_argument('--beta', type=float, default=1,\n",
    "                    help=('coefficient of the regularization term on '\n",
    "                          'clustering'))\n",
    "\"\"\"\n",
    "beta = 1e-5\n",
    "\"\"\"\n",
    "parser.add_argument('--latent_dim', type=int, default=10,\n",
    "                    help='latent space dimension')\n",
    "\"\"\"\n",
    "latent_dim = 10\n",
    "n_channels = 1\n",
    "is_MLP_AE = True\n",
    "\n",
    "if(is_MLP_AE):\n",
    "    input_dim = 784\n",
    "    dcn_autoencoder = DCNAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim)\n",
    "else:  \n",
    "    input_dim = 1\n",
    "    dcn_autoencoder = DCNCDAutoencoder(device=device, n_clusters=n_clusters, input_dim=input_dim, latent_dim=latent_dim, n_channels=n_channels) \n",
    "dcn_autoencoder.set_general_training_variables(dataloader=dataloader, batch_size=batch_size)\n",
    "dcn_autoencoder.set_pretraining_variables(n_pret_epochs=n_pret_epochs, pret_lr=pret_lr)\n",
    "dcn_autoencoder.set_training_variables(n_epochs=n_epochs, lr=lr, lamda=lamda, beta=beta )\n",
    "dcn_autoencoder.set_path_variables(path_to_module=path_to_module, dataset_name=dataset_name)\n",
    "dcn_autoencoder.set_path()\n",
    "dcn_autoencoder = dcn_autoencoder.to(device)\n",
    "\n",
    "pretrain = True\n",
    "if(pretrain):\n",
    "    dcn_autoencoder.pretrain_autoencoder()\n",
    "    dcn_autoencoder.save_pretrained_weights()\n",
    "else:\n",
    "    model_save_path = dcn_autoencoder.data_dir_path + '/Weigths/autoencoder_weights.pth'\n",
    "    dcn_autoencoder.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fcf5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dcn_autoencoder.train_autoencoder()\n",
    "cluster_centers = dcn_autoencoder.get_cluster_centers()\n",
    "_, dcn_autoencoder_reduced_data, labels = dcn_autoencoder.get_latent_data()\n",
    "General_Functions().save_excel(dcn_autoencoder.data_dir_path, dcn_autoencoder.df_eval)\n",
    "visualization.plot_tsne(dcn_autoencoder_reduced_data, labels, labels, cluster_centers, dcn_autoencoder.data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c846f6",
   "metadata": {},
   "source": [
    "### Pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA object\n",
    "pca = PCA(n_components=2)  # Choose the number of components\n",
    "\n",
    "# Fit and transform the data to the lower-dimensional space\n",
    "pca_reduced_data = pca.fit_transform(data_np)\n",
    "\n",
    "visualization.plot(pca_reduced_data, labels, labels, np.empty(0), \"./Results/r100/PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b56de",
   "metadata": {},
   "source": [
    "### Svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20471e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Truncated SVD for dimensionality reduction\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd_reduced_data = svd.fit_transform(data_np)\n",
    "\n",
    "visualization.plot(svd_reduced_data, labels, labels, np.empty(0), \"./Results/r100/SVD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d77675",
   "metadata": {},
   "source": [
    "### Nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75676677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NMF for dimensionality reduction\n",
    "nmf = NMF(n_components=2)\n",
    "nmf_reduced_data = nmf.fit_transform(data_np)\n",
    "\n",
    "visualization.plot(nmf_reduced_data, labels, labels, np.empty(0), \"./Results/r100/NMF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552a3ce",
   "metadata": {},
   "source": [
    "### Lle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dadfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)  # Adjust n_neighbors as needed\n",
    "lle_reduced_data = lle.fit_transform(data_np)\n",
    "\n",
    "visualization.plot(lle_reduced_data, labels, labels, np.empty(0), \"./Results/r100/LLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bacf012",
   "metadata": {},
   "source": [
    "### LapEig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_embedding = SpectralEmbedding(n_components=2, affinity='rbf')\n",
    "spectral_reduced_data = spectral_embedding.fit_transform(data_np)\n",
    "\n",
    "visualization.plot(spectral_reduced_data, labels, labels, np.empty(0), \"./Results/r100/LapEig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704785d9",
   "metadata": {},
   "source": [
    "### Sae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
